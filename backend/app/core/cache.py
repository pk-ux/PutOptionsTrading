"""
Caching layer with Redis support and in-memory fallback
- Portions generated by AI

Provides caching for:
- Stock prices (1 minute TTL - Yahoo is real-time)
- Options chains (5 minutes TTL - Massive data is 15-min delayed anyway)
- News (15 minutes TTL)
"""

import json
import hashlib
from typing import Any, Optional
from datetime import datetime, timedelta
from functools import lru_cache

# Try to import redis, fall back to in-memory if not available
try:
    import redis
    REDIS_AVAILABLE = True
except ImportError:
    REDIS_AVAILABLE = False
    print("Redis not installed. Using in-memory cache (not suitable for production).")

from .config import get_settings


# TTL constants (in seconds)
CACHE_TTL_STOCK_PRICE = 180  # 3 minutes (good balance between freshness and speed)
CACHE_TTL_OPTIONS_CHAIN = 300  # 5 minutes
CACHE_TTL_NEWS = 900  # 15 minutes


class InMemoryCache:
    """
    Simple in-memory cache for local development.
    NOT suitable for production with multiple workers.
    """
    
    def __init__(self):
        self._cache: dict[str, tuple[Any, datetime]] = {}
        print("Using in-memory cache (for local development only)")
    
    def get(self, key: str) -> Optional[str]:
        """Get value from cache if not expired"""
        if key in self._cache:
            value, expires_at = self._cache[key]
            if datetime.now() < expires_at:
                return value
            else:
                # Expired, remove it
                del self._cache[key]
        return None
    
    def set(self, key: str, value: str, ex: int = 300) -> None:
        """Set value with expiration (ex = seconds)"""
        expires_at = datetime.now() + timedelta(seconds=ex)
        self._cache[key] = (value, expires_at)
    
    def delete(self, key: str) -> None:
        """Delete a key from cache"""
        if key in self._cache:
            del self._cache[key]
    
    def flushall(self) -> None:
        """Clear all cached data"""
        self._cache.clear()
    
    def ping(self) -> bool:
        """Check if cache is available"""
        return True


class RedisCache:
    """
    Redis cache wrapper for production use.
    Supports multiple workers and horizontal scaling.
    """
    
    def __init__(self, redis_url: str):
        self._client = redis.from_url(redis_url, decode_responses=True)
        # Test connection
        try:
            self._client.ping()
            print(f"Connected to Redis successfully")
        except redis.ConnectionError as e:
            raise ConnectionError(f"Could not connect to Redis: {e}")
    
    def get(self, key: str) -> Optional[str]:
        """Get value from Redis"""
        return self._client.get(key)
    
    def set(self, key: str, value: str, ex: int = 300) -> None:
        """Set value with expiration (ex = seconds)"""
        self._client.set(key, value, ex=ex)
    
    def delete(self, key: str) -> None:
        """Delete a key from cache"""
        self._client.delete(key)
    
    def flushall(self) -> None:
        """Clear all cached data (use with caution!)"""
        self._client.flushall()
    
    def ping(self) -> bool:
        """Check if Redis is available"""
        try:
            self._client.ping()
            return True
        except:
            return False


# Global cache instance
_cache_instance: Optional[InMemoryCache | RedisCache] = None


def get_cache() -> InMemoryCache | RedisCache:
    """
    Get or create the cache instance.
    Uses Redis if REDIS_URL is configured, otherwise falls back to in-memory.
    """
    global _cache_instance
    
    if _cache_instance is not None:
        return _cache_instance
    
    settings = get_settings()
    redis_url = getattr(settings, 'REDIS_URL', None)
    
    if redis_url and REDIS_AVAILABLE:
        try:
            _cache_instance = RedisCache(redis_url)
            return _cache_instance
        except ConnectionError as e:
            print(f"Redis connection failed, falling back to in-memory: {e}")
    
    # Fallback to in-memory cache
    _cache_instance = InMemoryCache()
    return _cache_instance


def make_cache_key(prefix: str, *args, **kwargs) -> str:
    """
    Generate a consistent cache key from prefix and arguments.
    
    Example:
        make_cache_key("options", "AAPL", max_dte=45, min_dte=15)
        -> "options:AAPL:hash_of_kwargs"
    """
    key_parts = [prefix] + [str(a) for a in args]
    
    if kwargs:
        # Sort kwargs for consistent ordering
        sorted_kwargs = sorted(kwargs.items())
        kwargs_str = json.dumps(sorted_kwargs)
        kwargs_hash = hashlib.md5(kwargs_str.encode()).hexdigest()[:8]
        key_parts.append(kwargs_hash)
    
    return ":".join(key_parts)


# Check if caching is disabled
def is_cache_disabled() -> bool:
    """Check if caching is disabled via CACHE_DISABLED env var"""
    settings = get_settings()
    return getattr(settings, 'CACHE_DISABLED', False)


# Convenience functions for common cache operations

def cache_get_json(key: str) -> Optional[Any]:
    """Get JSON value from cache"""
    if is_cache_disabled():
        return None
    cache = get_cache()
    value = cache.get(key)
    if value:
        try:
            return json.loads(value)
        except json.JSONDecodeError:
            return None
    return None


def cache_set_json(key: str, value: Any, ttl: int = 300) -> None:
    """Set JSON value in cache with TTL"""
    if is_cache_disabled():
        return
    cache = get_cache()
    cache.set(key, json.dumps(value), ex=ttl)


def get_cached_stock_price(symbol: str) -> Optional[float]:
    """Get cached stock price"""
    key = make_cache_key("price", symbol)
    return cache_get_json(key)


def set_cached_stock_price(symbol: str, price: float) -> None:
    """Cache stock price (1 minute TTL)"""
    key = make_cache_key("price", symbol)
    cache_set_json(key, price, ttl=CACHE_TTL_STOCK_PRICE)


def get_cached_options_chain(symbol: str, config_hash: str) -> Optional[list]:
    """Get cached options chain"""
    key = make_cache_key("options", symbol, config_hash)
    return cache_get_json(key)


def set_cached_options_chain(symbol: str, config_hash: str, options: list) -> None:
    """Cache options chain (5 minutes TTL)"""
    key = make_cache_key("options", symbol, config_hash)
    cache_set_json(key, options, ttl=CACHE_TTL_OPTIONS_CHAIN)


def get_cached_news(symbol: str) -> Optional[list]:
    """Get cached news"""
    key = make_cache_key("news", symbol)
    return cache_get_json(key)


def set_cached_news(symbol: str, news: list) -> None:
    """Cache news (15 minutes TTL)"""
    key = make_cache_key("news", symbol)
    cache_set_json(key, news, ttl=CACHE_TTL_NEWS)


def get_config_hash(config: dict) -> str:
    """Generate a hash for the config to use in cache keys"""
    config_str = json.dumps(config, sort_keys=True)
    return hashlib.md5(config_str.encode()).hexdigest()[:8]
